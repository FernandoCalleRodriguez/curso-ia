import os
import lancedb
from dotenv import load_dotenv

# --- IMPORTS DE ORQUESTACI√ìN (CAPA 6) ---
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langchain_core.prompts import ChatPromptTemplate

# 1. Configuraci√≥n
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# --- HERRAMIENTAS (TOOLS) ---

@tool
def consultar_knowledge_base(query: str) -> str:
    """
    √ösalo para responder preguntas te√≥ricas, buscar opiniones, consejos
    o contenido espec√≠fico dentro del documento PDF/Curso.
    """
    print(f"\n   ü¶ú [LangChain Tool] RAG activado: '{query}'")
    
    # L√≥gica de resilencia de rutas (para que no falle por carpetas)
    db_paths = ["../lancedb_data", "./lancedb_data"]
    db_path = next((p for p in db_paths if os.path.exists(p)), None)
    
    if not db_path:
        return "Error cr√≠tico: No encuentro la carpeta lancedb_data."

    try:
        # Conexi√≥n a LanceDB (Capa 1)
        db = lancedb.connect(db_path)
        tbl = db.open_table("documentos")
        
        # Embeddings "on the fly" usando cliente raw para velocidad
        import google.genai as genai
        client_raw = genai.Client(api_key=GOOGLE_API_KEY)
        q_res = client_raw.models.embed_content(model="text-embedding-004", contents=query)
        q_vec = [float(x) for x in q_res.embeddings[0].values]
        
        # Retrieval
        results = tbl.search(q_vec).limit(3).to_pandas()
        
        # Formateo de salida
        contexto = "\n".join([f"- {row['text'][:300]}..." for _, row in results.iterrows()])
        return contexto if contexto else "No hay informaci√≥n en el PDF sobre esto."
        
    except Exception as e:
        return f"Error leyendo DB: {e}"

@tool
def calcular_horas_estudio(semanas: int, horas_diarias: float) -> str:
    """
    √ösalo SOLO para realizar c√°lculos matem√°ticos num√©ricos sobre tiempo y planificaci√≥n.
    """
    print(f"\n   ü¶ú [LangChain Tool] Calculadora: {semanas} semanas, {horas_diarias}h/d√≠a")
    total = semanas * 7 * horas_diarias
    return f"El c√°lculo matem√°tico exacto es: {total} horas totales."

# --- ARQUITECTURA DEL AGENTE ---

def main():
    print("--- AGENTE ORQUESTADOR (LANGCHAIN + GEMINI 1.5) ---")
    
    # 1. El Cerebro (LLM) - Usamos Gemini Pro que es estable en LangChain
    llm = ChatGoogleGenerativeAI(
        model="gemini-flash-latest",
        temperature=0,
        google_api_key=GOOGLE_API_KEY,
        convert_system_message_to_human=True
    )

    # 2. El Kit de Herramientas
    tools = [consultar_knowledge_base, calcular_horas_estudio]

    # 3. & 4. Ensamblaje del Agente (Forma moderna con LangGraph)
    # LangGraph crea un grafo de ejecuci√≥n que maneja el flujo autom√°ticamente
    agent_executor = create_react_agent(llm, tools)

    # 5. Bucle de Interacci√≥n
    while True:
        user_input = input("\nUsuario: ")
        if user_input.lower() in ["salir", "exit"]:
            break
            
        try:
            # LangGraph usa un formato diferente - recibe mensajes
            response = agent_executor.invoke({"messages": [("user", user_input)]})
            # La respuesta viene en el √∫ltimo mensaje
            print(f"ü§ñ Agente: {response['messages'][-1].content}")
            
        except Exception as e:
            print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    main()